### ğŸ¥ Teste TÃ©cnico â€“ Intuitive Care

**Candidato:** Joseph Borges Morais  
**Perfil:** AcadÃªmico de Bacharelado em Sistemas de InformaÃ§Ã£o â€“ 6Âº Semestre (IFBA)  
**Foco:** Back-end Development & Data Engineering

---

### ğŸ—ï¸ Arquitetura do Projeto

O projeto foi estruturado seguindo o modelo de pipeline **ETL (Extract, Transform, Load)**, garantindo a separaÃ§Ã£o de responsabilidades entre a coleta, o tratamento e a persistÃªncia dos dados.

---

### ğŸš€ Guia de ExecuÃ§Ã£o (Passo a Passo)

Para garantir a integridade dos dados, siga rigorosamente a ordem abaixo:

#### 1. PreparaÃ§Ã£o do Ambiente

```bash
# Criar o ambiente virtual
python -m venv .venv

# Ativar o ambiente virtual
# Windows
.venv\Scripts\activate

# Linux/macOS
source .venv/bin/activate

# Instalar dependÃªncias principais
pip install pandas requests beautifulsoup4 sqlalchemy psycopg2-binary
```

---

#### 2. ConfiguraÃ§Ã£o do Banco de Dados

- Crie um banco de dados PostgreSQL chamado `intuitive_db`.
- Execute o script `schema.sql` para criar tabelas, chaves primÃ¡rias, chaves estrangeiras e Ã­ndices.

---

#### 3. ExecuÃ§Ã£o do Pipeline ETL

- **ExtraÃ§Ã£o:** `python main.py`
- **Tratamento:** `python transformacao.py`
- **Enriquecimento:** `python enriquecimento.py`
- **InteligÃªncia:** `python agregacao.py`

---

#### 4. Carga de Dados (Load)

Execute:
```bash
python importacao.py
```

---

#### 5. ValidaÃ§Ã£o e AnÃ¡lise

Execute as queries contidas em `analise.sql` no cliente SQL (ex: pgAdmin).

---

### ğŸ§  DecisÃµes de Engenharia e Trade-offs

#### Processamento e MemÃ³ria
Processamento incremental para evitar erros de **Out of Memory (OOM)**.

#### Modelagem de Dados
Uso de tabelas normalizadas com **Foreign Keys**.

#### PrecisÃ£o Financeira
Uso de `DECIMAL(18,2)` para garantir exatidÃ£o.

---

### ğŸ“Š SQL Analytics

```sql
((valor_periodo_atual - valor_periodo_anterior) 
 / valor_periodo_anterior) * 100
```

---

### ğŸ“‚ Estrutura de Arquivos

- `saida/`
- `schema.sql`
- `importacao.py`

